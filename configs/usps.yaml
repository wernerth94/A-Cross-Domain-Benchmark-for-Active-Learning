classifier:
  type: MLP
  hidden: [24, 12]

classifier_embedded:
  type: Linear

pretext_encoder:
  type: MLP
  hidden: [64, 64, 64]
  feature_dim: 48

pretext_optimizer:
  type: NAdam
  lr: 0.000126317776435636
  weight_decay: 4.84494513850282E-05
  lr_scheduler: cosine
  lr_scheduler_decay: 0.0112630748098282

pretext_transforms:
  gauss_scale: 0.138332470346464

pretext_clr_loss:
  temperature: 0.127993566363245

pretext_training:
  batch_size: 227
  epochs: 200
