# Dataset: 
Cifar10Encoded
Budget: 350
Seeding points per class: 1
Classifier Batch Size: 64
Source: TorchVision
Normalization: Linear between [-1..1]
Classifier: ResNet18 

# Agent: 
ShannonEntropy 

# Config: 
dataset: {'budget': 5000, 'classifier_fitting_mode': 'finetuning', 'initial_points_per_class': 100, 'classifier_batch_size': 64, 'validation_split': 0.04} 
classifier: {'type': 'Resnet18'} 
optimizer: {'type': 'NAdam', 'lr': 0.001, 'weight_decay': 0.0} 
dataset_embedded: {'encoder_checkpoint': 'encoder_checkpoints/cifar10_27.03/model_seed1.pth.tar', 'budget': 350, 'classifier_fitting_mode': 'from_scratch', 'initial_points_per_class': 1, 'classifier_batch_size': 64} 
classifier_embedded: {'type': 'Linear'} 
optimizer_embedded: {'type': 'NAdam', 'lr': 0.00171578341563099, 'weight_decay': 2.38432342659786e-05} 
pretext_encoder: {'type': 'Resnet18', 'feature_dim': 128} 
pretext_optimizer: {'type': 'SGD', 'lr': 0.4, 'nesterov': False, 'weight_decay': 0.0001, 'momentum': 0.9, 'lr_scheduler': 'cosine', 'lr_scheduler_decay': 0.1} 
pretext_clr_loss: {'temperature': 0.1} 
pretext_training: {'batch_size': 512, 'epochs': 500} 
current_run_info: {'data_folder': '../datasets', 'run_id': 44, 'agent_seed': 1, 'pool_seed': 1, 'model_seed': 1, 'agent': 'entropy', 'dataset': 'cifar10', 'query_size': 5, 'encoded': True, 'restarts': 1, 'experiment_postfix': None} 
